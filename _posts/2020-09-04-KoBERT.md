---
category: study
layout: post
title: KoBERT
---

### KoBERT란?

KoBERT란 Korean BERT의 줄임말로, BERT가 언어모델인 것을 생각하면 한국어 언어모델에 해당하는 것으로 추정된다.

KoBERT는 SKT의 T-Brain에서 기존 BERT의 한국어 성능 한계를 극복하기 위해 개발된 모델이고, 위키피디아, 뉴스 등에서 수집한 한국어 문장으로 학습을 했다고 한다.

토크나이저로는 기학습된 Sentencepiece tokenizer를 사용한다.


KoBERT 깃허브 링크: <a href="https://github.com/SKTBrain/KoBERT">link</a>

+) 20201209 KoBART 모델도 새로 나왔다.

KoBART 깃허브 링크: <a href="https://github.com/SKT-AI/KoBART">link</a>


<del>근데 KoBERT도 그렇고 KoBART도 그렇고 논문이나 설명 따로 없이 코드만 배포하는건가.. 내가 못찾은건가.. </del>
