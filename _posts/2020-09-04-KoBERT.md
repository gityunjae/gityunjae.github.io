---
category: study
layout: post
title: KoBERT
---

### KoBERT란?

KoBERT란 Korean BERT의 줄임말로, BERT가 언어모델인 것을 생각하면 한국어 언어모델에 해당하는 것으로 추정된다.

KoBERT는 SKT의 T-Brain에서 기존 BERT의 한국어 성능 한계를 극복하기 위해 개발된 모델이고, 위키피디아, 뉴스 등에서 수집한 한국어 문장으로 학습을 했다고 한다.

토크나이저로는 기학습된 Sentencepiece tokenizer를 사용한다.


KoBERT 깃허브 링크: <a href="https://github.com/SKTBrain/KoBERT">link</a>
