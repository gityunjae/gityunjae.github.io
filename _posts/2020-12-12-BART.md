---
category: papers
layout: post
title: BART
---

제목: BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension

저자: Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Ves Stoyanov, Luke Zettlemoyer

발행: 2020, Association for Computational Linguistics

BART는 seq2seq 모델 학습을 위해 denoising autoencoder 모델이다. Denoising AutoEncoder는 2008년 몬트리올 대학교의 Pascal Vincent, Yoshua Bengio 등이 발표한 "Extracting and Composing Robust Features with Denoising AutoEncoder"에서 제안된 개념으로, 자율학습을 이용하여 입력 데이터에 숨어있는 중요한 특징을 파악하는 용도로 개발되었다[1].


출처:<br>
[1] <a href="http://blog.naver.com/PostView.nhn?blogId=laonple&logNo=220891144201&categoryNo=0&parentCategoryNo=0&viewDate=&currentPage=1&postListTopCurrentPage=1&from=postView">라온피플</a>, 네이버 블로그<br>
