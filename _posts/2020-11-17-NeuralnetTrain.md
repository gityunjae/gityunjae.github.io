---
category: DLfS
layout: post
title: 4. 신경망 학습
---
기계학습에서 학습이란 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것을 말한다.
학습의 목표는 손실함수의 결과값을 가장 작게 만드는 가중치 매개변수를 찾는 것인데, 손실함수의 결과값을 작게 만드는 방법으로는 함수의 기울기를 활용하는 경사법 등이 있다.

### 데이터 학습
기계가 스스로 핛브을 하면 가중치 매개변수의 값을 데이터를 보고 자동으로 결정할 수 있는데, 이것이 사람이 수작업으로 매개변수를 찾는 것에 비해 어떻게 이득일까?

실제 신경망에서의 매개변수는 수천~수만개이고, 층을 깊게 하면 수억개까지도 필요할 수 있어 수작업이 사실상 불가능하다.

기계학습에서는 사람의 개입을 최소화하고 수집한 데이터로부터 패턴을 찾는다. 예를 들어 이미지에서 특징을 추출하여 특징의 패턴을 가지고 학습을 하는데, 이 때 SIFT, SURF, HOG등의 특징을 사용하여 이미지를 벡터로 변환하고, 이러한 벡터들을 SVM, KNN등으로 학습한다. 이렇게 데이터에서 규칙을 찾는 것은 기계가 하지만, 이미지를 벡터로 변환할 때 사용하는 특징은 사람이 설계한다.

신경망을 사용하게 되는 경우 이미지에 포함된 특성 또한 기계가 스스로 학습하는데, 다시 말하면 신경망은 모든 문제를 주어진 데이터 그대로 입력 데이터로 활용해서 end-to-end 방식으로 사람의 개입 없이도 학습할 수 있다.

기계학습에서는 훈련 데이터와 시험 데이터를 나누어 학습과 실험을 수행하는데, 훈련 데이터로 학습한 후 시험데이터로 훈련한 모델의 실력을 평가한다. 이 때 시험 데이터를 나누는 이유는 훈련 데이터에 포함되지 않는 새로운 데이터로도 문제를 올바르게 푸는 능력인 '범용 능력'을 제대로 평가하기 위해서이다. 특정 데이터셋에 지나치게 최적화된 상태를 오버피팅이라고 하는데, 기계학습에서는 새로 들어온 데이터에 대해서도 문제를 잘 해결할 수 있어야 하기 때문에 오버피팅을 피하는 것이 중요하다.

### 손실 함수
신경망 학습에서는 현재의 상태를 하나의 지표로 표현하고, 이 지표를 가장 좋게 만들어주는 가중치 매개변수 값을 탐색한다. <b>손실함수</b>(loss function, 비용함수(cost function)이라고 부르기도 한다)가 이 지표에 해당한다. 손실함수로는 일반적으로 오차제곱합과 교차엔트로피 오차를 사용한다.

* 오차 제곱합(sum of squares for error, SSE)
(img)
손실함수의 출력이 작으면 정답 레이블과의 오차가 작고 정답에 더 가깝다고 판단할 수 있다.

* 교차 엔트로피 오차(cross entropy error, CEE)
(img)
실질적으로 정답에 대응되는 추정값의 자연로그 값과 동일하다. 이 방법에서도 정답에 해당하는 출력이 커질수록 오차가 작아지고, 정답에 해당하는 출력이 작아질수록 오차가 커진다.
