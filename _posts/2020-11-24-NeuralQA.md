---
category: papers
layout: post
title: NeuralQA
---

제목: NeuralQA: A Usable Library for Question Answering (Contextual Query Expansion + BERT) on Large Datasets

저자: Victor Dibia

발행년도: 2020

Neural QA는 큰 데이터셋에 사용할 수 있는 QA 라이브러리이다. QA subtask에도 적용할 수 있고, contextual query expansion을 제안하고 구현할 수 있다. 또한 유동적인 ui를 제공한다.

## 1. Introduction
자연어 질의에 대한 정확한 답을 제공하는 능력은 다양한 분야에서 사용자 경험을 개선시킬 수 있다. 
Search 분야나 information retrieval 분야, 최근에 연구되는 오픈 도메인 대화 시스템에도 적용될 수 있고, 기업 단위에서는 거대한 비정형 데이터에서 지식을 추출할 때 큰 도움이 될 수 있다.

지금까지 오픈 도메인 QA를 개발하는 과정에서는 두 단계를 따랐다.
> 1. retriever가 연관된 document를 모두 가져온다.
> 2. reader인 machine reading comprehension model이 document들에서 답을 포함하는 범위를 찾는다.

retriever는 보통 sparse vector space를 사용해서 연산하는데, 보통 키워드 매칭 방식을 사용하고 vocabulary mismatch 문제(query의 단어와 document에서 같은 concept를 표현하는 단어가 다름)에 시달린다.
이러한 문제를 해결하기 위해 neural ranking을 사용하거나 dense representation을 사용하는 retrieval method을 사용하는 연구도 있었다.

dense representation을 사용하면 확실히 성능은 나아지지만 더 복잡해지고 느려지기 때문에 practical application을 제한하는 결과를 낳을 수 있다.

transformer 모델을 사용하자니 문장이 길어서 self-attention을 적용할 수가 없다. 이럴 때에는 document를 좀 더 작은 문단 단위로 쪼개줘야 한다.

근데 이렇게 요구사항들을 맞추면서 학습하려면 아무래도 cost-intensive하고, 더 간단한 방법으로도 충분히 괜찮은 결과를 낼 수 있기 때문에 굳이 더 복잡한 모델을 사용할 필요는 없어 보인다.

reader 모델의 경우 특정 도메인에 적용했을 때 직관적이지 않은 부분들에서 제대로 일을 수행하지 못하는 경우가 있는데, 이럴 때에는 디버깅이나 결과가 왜 그렇게 나왔는지 이해하기 위해서 시각적인 인터페이스를 주면 훨씬 도움이 된다.

이 논문에서는 이러한 한계점들을 보완하기 위해서 Neural QA를 제안한다.
이 논문이 기여하는 바는 다음과 같다.
> * QA 시스템 구현을 위한 쓰기 쉬운 end-to-end 라이브러리 제안
> * vocabulary mismatch 문제를 해결하기 위해서 MLM을 사용한 contextual query expansion method 제안
> * 읽어온 자료를 reader로 넘기기 전에 연관된 snippet을 추출하는 방법인 RelSnip 제안

아무튼 NeuralQA는 이전의 QA system deployment를 개선하고 머신러닝 모델 이해를 위한 시각적인 인터페이스를 제공한다.

## 2. The Question Answering Pipeline
QA pipeline에 자주 쓰이는 subtask들 중 NeuralQA에서 구현한 subtask들에 대해 알아보자.
### Document Retrieval
QA의 첫 단계는 후보 passage들을 가져오는 것이다. 
기존의 접근법들을 보면 BM25, Tfidf 등의 희소 벡터 공간 모델을 사용하는 경우가 많은데, 희소한 벡터를 사용하는 sparse representation은 키워드에 의존적이고, vocabulary mismatch 문제가 자주 발생한다.
또한 sparse representation을 사용하면 관련있는 자료를 찾아오는데 필요한 문맥 정보가 부족할 수도 있다.

이러한 한계점을 보완하기 위해 re-ranking retrived document를 사용하는 방법들이 연구되었고, retrieval에 유용한 쿼리나 document의 표현법을 학습시키는 방법, 그리고 query를 벡터로 맵핑하고 document를 유사 벡터로 맵핑하는 dual encoder 방식등이 연구되고 있다.

### Query Expansion
query expansion 또한 vocabulary mismatch 문제를 해결하기 위해 제안된 방법이다.
이를 위해 relevance 모델을 사용하여 질의에 포함된 함축된 정보를 사용하는 방식이나 expansion term을 특정화 하기 위한 임베딩을 하는 워드 임베딩을 사용하는 방식 등이 연구되었는데 word2vec 임베딩과 relevance model을 결합한 방식을 사용하는 것이 좋은 결과를 낸다고 한다.

논문의 저자는 Masked Language Model(MLM)을 사용하여 contextual embedding으로 query expansion term을 생성하는 방법을 시도하였다.

### Document Reading
QA 모델은 base representation과 output feed-forward layer로 이루어져있고, 두 가지 점수를 사용한다.
1. 각 입력 토큰이 정답 영역의 시작 부분일 확률을 나타내는 점수
2. 각 입력 토큰이 정답 영역의 끝 부분일 확률을 나타내는 점수

## 3. NeuralQA System Architecture
NeuralQA는 크게 user interface, retriever, expander, 그리고 reader로 이루어져 있고, 파이썬으로 작성되었다.

### Retriever
보통 document를 가져오면 길이가 일정하지 않은데 reader 모델들은 보통 최대 길이 제한을 가지고 있기 때문에 document를 그대로 넣어주면 이를 chunk로 쪼개고 하는데 더 시간이 든다.

이를 해결하기 위해 NeuralQA에서는 RelSnip이라는 document를 더 작은 단위로 잘라주는 방법을 사용한다. RelSnip이 동작하는 과정은 읽어온 document에 하이라이트를 해서 BM25 알고리즘을 사용해 특정 크기로 document를 잘라준다. 그리고 연관성이 높은 n fragment씩 붙여주면 이를 리더에서 처리하게 된다.

### Expander
Contextual Query Expansion은 타겟 document 말뭉치에 대해 파인튜닝 된 MLM 모델이 함축적인 정보를 담고 있어서 관련있는 질의 확장 용어를 알아챌 수 있다는 추측을 기반으로 한다.
질의 확장을 위해 원래 질의의 내용을 바꾸지 않고 노이즈를 최소한으로 하는 선에서 재현율을 높이기 위해 추가적인 토큰을 사용한다.

해당 논문의 CQE에서는 expansion 후보 토큰들을 가져와서 SpaCy 라이브러리로 pos 태깅을 하고 원래 질의에 위의 후보들을 마스킹해서 mlm이 해당 마스킹 위치에 나올 내용들을 예측하게 한다. 그리고 모델이 예측한 토큰들을 원래 질의에서 expansion term으로 추가해준다.

이 때 원래 질의와 너무 관련 없는 토큰들을 제하기 위해 confidence score가 일정 threshold를 넘는 토큰들을 사용하고, conservative 필터를 사용해서 noun과 adjective만을 추가한다. 그리고 duplicate terms, punctuation, 그리고 불용어를 제거해준다.

### Reader
리더의 인터페이스에는 쿼리와 document를 입력했을 때 answer span을 예측하는 부분이 출력된다. 뒤에서는 Transformer API를 사용한 QA 모델이 돌아가고 있는데, 토큰이 최대 길이가 넘어가면 자동으로 더 작게 잘라서 각 chunk에 대한 정답 영역을 구한다. 모든 정답을 다 모아서 gradient based 설명을 생성한다.

인터페이스에서 추구하는 바는 사용자가 질의를 잘 수행하고 모델이 어떻게 돌아가는지 이해할 수 있게 하는 것이다.
먼저 가져온 document에서 어느 부분이 relevance ranking에 기여했는지를 highlight 해준다. 그 다음에 설명을 생성해서 입력의 어떤 부분이 정답 영역과 가장 연관이 깊었는지를 보여준다. 

scalability가 좋고, 도커를 사용하고, 데스크탑과 모바일에 최적화되어있다.

### Configuration and Workflow
NerualQA 사용시 command line interface를 사용하는데 파라미터를 명시하게 되어있다. 실행할 때 사용자가 커맨트라인에 config YAML 파일의 위치를 입력하는데 입력 위치에 파일이 없으면 NeuralQA가 디폴트로 설정해준다. 

### Persona
NeuralQA는 다양한 상황과 사람들을 위해 디자인 되었고, 이를 위해 두 가지 페르소나를 설정하였다. 하나는 data scientist이고 다른 하나는 Engineering team이다. 각각의 사람이 각각의 상황에서 어떻게 NeuralQA를 사용했을지 시나리오가 나와있다.

## 4. Conclusion
결론적으로 NeuralQA는 큰 데이터셋에 사용하기 좋은 QA 라이브러리이고, 커스텀 데이터셋에 대한 QA 모델들이 필요한 개발자들과 flexible한 QA 인터페이스가 필요한 기업들에게 유용하다.
NeuralQA는 현재도 Solr retriever 지원, 추가적인 모델 설명 방법 개발, 그리고 추가적인 질의 확장 방법 연구등을 활발히 연구하고 있다.

github link: <a href="https://github.com/victordibia/neuralqa">https://github.com/victordibia/neuralqa</a>
