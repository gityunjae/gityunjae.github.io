---
category: papers
layout: post
title: NeuralQA
---

제목: NeuralQA: A Usable Library for Question Answering (Contextual Query Expansion + BERT) on Large Datasets

저자: Victor Dibia

발행년도: 2020

Neural QA는 큰 데이터셋에 사용할 수 있는 QA 라이브러리이다. QA subtask에도 적용할 수 있고, contextual query expansion을 제안하고 구현할 수 있다. 또한 유동적인 ui를 제공한다.

## 1. Introduction
자연어 질의에 대한 정확한 답을 제공하는 능력은 다양한 분야에서 사용자 경험을 개선시킬 수 있다. 
Search 분야나 information retrieval 분야, 최근에 연구되는 오픈 도메인 대화 시스템에도 적용될 수 있고, 기업 단위에서는 거대한 비정형 데이터에서 지식을 추출할 때 큰 도움이 될 수 있다.

지금까지 오픈 도메인 QA를 개발하는 과정에서는 두 단계를 따랐다.
> 1. retriever가 연관된 document를 모두 가져온다.
> 2. reader인 machine reading comprehension model이 document들에서 답을 포함하는 범위를 찾는다.

retriever는 보통 sparse vector space를 사용해서 연산하는데, 보통 키워드 매칭 방식을 사용하고 vocabulary mismatch 문제(query의 단어와 document에서 같은 concept를 표현하는 단어가 다름)에 시달린다.
이러한 문제를 해결하기 위해 neural ranking을 사용하거나 dense representation을 사용하는 retrieval method을 사용하는 연구도 있었다.

dense representation을 사용하면 확실히 성능은 나아지지만 더 복잡해지고 느려지기 때문에 practical application을 제한하는 결과를 낳을 수 있다.

transformer 모델을 사용하자니 문장이 길어서 self-attention을 적용할 수가 없다. 이럴 때에는 document를 좀 더 작은 문단 단위로 쪼개줘야 한다.

근데 이렇게 요구사항들을 맞추면서 학습하려면 아무래도 cost-intensive하고, 더 간단한 방법으로도 충분히 괜찮은 결과를 낼 수 있기 때문에 굳이 더 복잡한 모델을 사용할 필요는 없어 보인다.

reader 모델의 경우 특정 도메인에 적용했을 때 직관적이지 않은 부분들에서 제대로 일을 수행하지 못하는 경우가 있는데, 이럴 때에는 디버깅이나 결과가 왜 그렇게 나왔는지 이해하기 위해서 시각적인 인터페이스를 주면 훨씬 도움이 된다.

이 논문에서는 이러한 한계점들을 보완하기 위해서 Neural QA를 제안한다.
이 논문이 기여하는 바는 다음과 같다.
> * QA 시스템 구현을 위한 쓰기 쉬운 end-to-end 라이브러리 제안
> * vocabulary mismatch 문제를 해결하기 위해서 MLM을 사용한 contextual query expansion method 제안
> * 읽어온 자료를 reader로 넘기기 전에 연관된 snippet을 추출하는 방법인 RelSnip 제안

아무튼 NeuralQA는 이전의 QA system deployment를 개선하고 머신러닝 모델 이해를 위한 시각적인 인터페이스를 제공한다.

## 2. The Question Answering Pipeline

## 3. NeuralQA System Architecture

## 4. Conclusion
