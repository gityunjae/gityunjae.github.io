---
category: papers
layout: post
title: NeuralQA
---

제목: NeuralQA: A Usable Library for Question Answering (Contextual Query Expansion + BERT) on Large Datasets

저자: Victor Dibia

발행년도: 2020

Neural QA는 큰 데이터셋에 사용할 수 있는 QA 라이브러리이다. QA subtask에도 적용할 수 있고, contextual query expansion을 제안하고 구현할 수 있다. 또한 유동적인 ui를 제공한다.

## 1. Introduction
자연어 질의에 대한 정확한 답을 제공하는 능력은 다양한 분야에서 사용자 경험을 개선시킬 수 있다. 
Search 분야나 information retrieval 분야, 최근에 연구되는 오픈 도메인 대화 시스템에도 적용될 수 있고, 기업 단위에서는 거대한 비정형 데이터에서 지식을 추출할 때 큰 도움이 될 수 있다.

지금까지 오픈 도메인 QA를 개발하는 과정에서는 두 단계를 따랐다.
> 1. retriever가 연관된 document를 모두 가져온다.
> 2. reader인 machine reading comprehension model이 document들에서 답을 포함하는 범위를 찾는다.

retriever는 보통 sparse vector space를 사용해서 연산하는데, 보통 키워드 매칭 방식을 사용하고 vocabulary mismatch 문제(query의 단어와 document에서 같은 concept를 표현하는 단어가 다름)에 시달린다.
이러한 문제를 해결하기 위해 neural ranking을 사용하거나 dense representation을 사용하는 retrieval method을 사용하는 연구도 있었다.

dense representation을 사용하면 확실히 성능은 나아지지만 더 복잡해지고 느려지기 때문에 practical application을 제한하는 결과를 낳을 수 있다.

transformer 모델을 사용하자니 문장이 길어서 self-attention을 적용할 수가 없다. 이럴 때에는 document를 좀 더 작은 문단 단위로 쪼개줘야 한다.

근데 이렇게 요구사항들을 맞추면서 학습하려면 아무래도 cost-intensive하고, 더 간단한 방법으로도 충분히 괜찮은 결과를 낼 수 있기 때문에 굳이 더 복잡한 모델을 사용할 필요는 없어 보인다.

reader 모델의 경우 특정 도메인에 적용했을 때 직관적이지 않은 부분들에서 제대로 일을 수행하지 못하는 경우가 있는데, 이럴 때에는 디버깅이나 결과가 왜 그렇게 나왔는지 이해하기 위해서 시각적인 인터페이스를 주면 훨씬 도움이 된다.

이 논문에서는 이러한 한계점들을 보완하기 위해서 Neural QA를 제안한다.
이 논문이 기여하는 바는 다음과 같다.
> * QA 시스템 구현을 위한 쓰기 쉬운 end-to-end 라이브러리 제안
> * vocabulary mismatch 문제를 해결하기 위해서 MLM을 사용한 contextual query expansion method 제안
> * 읽어온 자료를 reader로 넘기기 전에 연관된 snippet을 추출하는 방법인 RelSnip 제안

아무튼 NeuralQA는 이전의 QA system deployment를 개선하고 머신러닝 모델 이해를 위한 시각적인 인터페이스를 제공한다.

## 2. The Question Answering Pipeline
QA pipeline에 자주 쓰이는 subtask들 중 NeuralQA에서 구현한 subtask들에 대해 알아보자.
### Document Retrieval
QA의 첫 단계는 후보 passage들을 가져오는 것이다. 
기존의 접근법들을 보면 BM25, Tfidf 등의 희소 벡터 공간 모델을 사용하는 경우가 많은데, 희소한 벡터를 사용하는 sparse representation은 키워드에 의존적이고, vocabulary mismatch 문제가 자주 발생한다.
또한 sparse representation을 사용하면 관련있는 자료를 찾아오는데 필요한 문맥 정보가 부족할 수도 있다.

이러한 한계점을 보완하기 위해 re-ranking retrived document를 사용하는 방법들이 연구되었고, retrieval에 유용한 쿼리나 document의 표현법을 학습시키는 방법, 그리고 query를 벡터로 맵핑하고 document를 유사 벡터로 맵핑하는 dual encoder 방식등이 연구되고 있다.

### Query Expansion
query expansion 또한 vocabulary mismatch 문제를 해결하기 위해 제안된 방법이다.
이를 위해 relevance 모델을 사용하여 질의에 포함된 함축된 정보를 사용하는 방식이나 expansion term을 특정화 하기 위한 임베딩을 하는 워드 임베딩을 사용하는 방식 등이 연구되었는데 word2vec 임베딩과 relevance model을 결합한 방식을 사용하는 것이 좋은 결과를 낸다고 한다.

논문의 저자는 Masked Language Model(MLM)을 사용하여 contextual embedding으로 query expansion term을 생성하는 방법을 시도하였다.

### Document Reading
QA 모델은 base representation과 output feed-forward layer로 이루어져있고, 두 가지 점수를 사용한다.
1. 각 입력 토큰이 정답 영역의 시작 부분일 확률을 나타내는 점수
2. 각 입력 토큰이 정답 영역의 끝 부분일 확률을 나타내는 점수

## 3. NeuralQA System Architecture

## 4. Conclusion
